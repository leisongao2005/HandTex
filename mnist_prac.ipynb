{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "device = 'mps' if torch.mps.is_available() else 'cpu'\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "layer_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(\n",
    "    MNIST('../', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    MNIST('../', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating One layer NN\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, data_len, layer_size):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=5, device=device),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(8, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 64, kernel_size=5, device=device),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(64, device=device),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.lin_layers = nn.Sequential(\n",
    "            nn.Linear(1024, 512, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 10, device=device),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.conv_layers(input)\n",
    "        output = self.lin_layers(output.view(-1, 1024))\n",
    "        logits = F.softmax(output, dim=1)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = SimpleNN(784, layer_size=layer_size)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "                        weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iteration: 0 Loss: 2.29712\n",
      "Epoch: 0 Iteration: 100 Loss: 1.56925\n",
      "Epoch: 0 Iteration: 200 Loss: 1.50909\n",
      "Epoch: 0 Iteration: 300 Loss: 1.47201\n",
      "Epoch: 0 Iteration: 400 Loss: 1.50853\n",
      "Epoch: 0 Iteration: 500 Loss: 1.48985\n",
      "Epoch: 0 Iteration: 600 Loss: 1.49922\n",
      "Epoch: 0 Iteration: 700 Loss: 1.51312\n",
      "Epoch: 0 Iteration: 800 Loss: 1.47798\n",
      "Epoch: 0 Iteration: 900 Loss: 1.50895\n",
      "Epoch: 1 Iteration: 0 Loss: 1.46628\n",
      "Epoch: 1 Iteration: 100 Loss: 1.51758\n",
      "Epoch: 1 Iteration: 200 Loss: 1.46762\n",
      "Epoch: 1 Iteration: 300 Loss: 1.48604\n",
      "Epoch: 1 Iteration: 400 Loss: 1.46679\n",
      "Epoch: 1 Iteration: 500 Loss: 1.51469\n",
      "Epoch: 1 Iteration: 600 Loss: 1.49775\n",
      "Epoch: 1 Iteration: 700 Loss: 1.46128\n",
      "Epoch: 1 Iteration: 800 Loss: 1.49599\n",
      "Epoch: 1 Iteration: 900 Loss: 1.48994\n",
      "Epoch: 2 Iteration: 0 Loss: 1.47363\n",
      "Epoch: 2 Iteration: 100 Loss: 1.46923\n",
      "Epoch: 2 Iteration: 200 Loss: 1.50005\n",
      "Epoch: 2 Iteration: 300 Loss: 1.47757\n",
      "Epoch: 2 Iteration: 400 Loss: 1.48450\n",
      "Epoch: 2 Iteration: 500 Loss: 1.47670\n",
      "Epoch: 2 Iteration: 600 Loss: 1.48443\n",
      "Epoch: 2 Iteration: 700 Loss: 1.47806\n",
      "Epoch: 2 Iteration: 800 Loss: 1.50461\n",
      "Epoch: 2 Iteration: 900 Loss: 1.47247\n",
      "Epoch: 3 Iteration: 0 Loss: 1.48371\n",
      "Epoch: 3 Iteration: 100 Loss: 1.46673\n",
      "Epoch: 3 Iteration: 200 Loss: 1.47695\n",
      "Epoch: 3 Iteration: 300 Loss: 1.48745\n",
      "Epoch: 3 Iteration: 400 Loss: 1.48147\n",
      "Epoch: 3 Iteration: 500 Loss: 1.46947\n",
      "Epoch: 3 Iteration: 600 Loss: 1.49675\n",
      "Epoch: 3 Iteration: 700 Loss: 1.49273\n",
      "Epoch: 3 Iteration: 800 Loss: 1.47723\n",
      "Epoch: 3 Iteration: 900 Loss: 1.47607\n",
      "Epoch: 4 Iteration: 0 Loss: 1.46920\n",
      "Epoch: 4 Iteration: 100 Loss: 1.46135\n",
      "Epoch: 4 Iteration: 200 Loss: 1.52978\n",
      "Epoch: 4 Iteration: 300 Loss: 1.46277\n",
      "Epoch: 4 Iteration: 400 Loss: 1.47862\n",
      "Epoch: 4 Iteration: 500 Loss: 1.47676\n",
      "Epoch: 4 Iteration: 600 Loss: 1.46176\n",
      "Epoch: 4 Iteration: 700 Loss: 1.46127\n",
      "Epoch: 4 Iteration: 800 Loss: 1.47697\n",
      "Epoch: 4 Iteration: 900 Loss: 1.46117\n",
      "Epoch: 5 Iteration: 0 Loss: 1.46208\n",
      "Epoch: 5 Iteration: 100 Loss: 1.48892\n",
      "Epoch: 5 Iteration: 200 Loss: 1.46133\n",
      "Epoch: 5 Iteration: 300 Loss: 1.46402\n",
      "Epoch: 5 Iteration: 400 Loss: 1.47854\n",
      "Epoch: 5 Iteration: 500 Loss: 1.48083\n",
      "Epoch: 5 Iteration: 600 Loss: 1.46255\n",
      "Epoch: 5 Iteration: 700 Loss: 1.46936\n",
      "Epoch: 5 Iteration: 800 Loss: 1.47687\n",
      "Epoch: 5 Iteration: 900 Loss: 1.47672\n",
      "Epoch: 6 Iteration: 0 Loss: 1.49120\n",
      "Epoch: 6 Iteration: 100 Loss: 1.49509\n",
      "Epoch: 6 Iteration: 200 Loss: 1.47337\n",
      "Epoch: 6 Iteration: 300 Loss: 1.46147\n",
      "Epoch: 6 Iteration: 400 Loss: 1.46196\n",
      "Epoch: 6 Iteration: 500 Loss: 1.49298\n",
      "Epoch: 6 Iteration: 600 Loss: 1.46548\n",
      "Epoch: 6 Iteration: 700 Loss: 1.46124\n",
      "Epoch: 6 Iteration: 800 Loss: 1.47703\n",
      "Epoch: 6 Iteration: 900 Loss: 1.46833\n",
      "Epoch: 7 Iteration: 0 Loss: 1.47680\n",
      "Epoch: 7 Iteration: 100 Loss: 1.46284\n",
      "Epoch: 7 Iteration: 200 Loss: 1.46134\n",
      "Epoch: 7 Iteration: 300 Loss: 1.50161\n",
      "Epoch: 7 Iteration: 400 Loss: 1.48305\n",
      "Epoch: 7 Iteration: 500 Loss: 1.46141\n",
      "Epoch: 7 Iteration: 600 Loss: 1.46555\n",
      "Epoch: 7 Iteration: 700 Loss: 1.46134\n",
      "Epoch: 7 Iteration: 800 Loss: 1.47811\n",
      "Epoch: 7 Iteration: 900 Loss: 1.49849\n",
      "Epoch: 8 Iteration: 0 Loss: 1.46190\n",
      "Epoch: 8 Iteration: 100 Loss: 1.46131\n",
      "Epoch: 8 Iteration: 200 Loss: 1.47484\n",
      "Epoch: 8 Iteration: 300 Loss: 1.48804\n",
      "Epoch: 8 Iteration: 400 Loss: 1.46193\n",
      "Epoch: 8 Iteration: 500 Loss: 1.49302\n",
      "Epoch: 8 Iteration: 600 Loss: 1.46195\n",
      "Epoch: 8 Iteration: 700 Loss: 1.46125\n",
      "Epoch: 8 Iteration: 800 Loss: 1.47692\n",
      "Epoch: 8 Iteration: 900 Loss: 1.47497\n",
      "Epoch: 9 Iteration: 0 Loss: 1.46383\n",
      "Epoch: 9 Iteration: 100 Loss: 1.46315\n",
      "Epoch: 9 Iteration: 200 Loss: 1.46247\n",
      "Epoch: 9 Iteration: 300 Loss: 1.46128\n",
      "Epoch: 9 Iteration: 400 Loss: 1.46989\n",
      "Epoch: 9 Iteration: 500 Loss: 1.46134\n",
      "Epoch: 9 Iteration: 600 Loss: 1.46139\n",
      "Epoch: 9 Iteration: 700 Loss: 1.48130\n",
      "Epoch: 9 Iteration: 800 Loss: 1.46498\n",
      "Epoch: 9 Iteration: 900 Loss: 1.46127\n",
      "Epoch: 10 Iteration: 0 Loss: 1.46278\n",
      "Epoch: 10 Iteration: 100 Loss: 1.47679\n",
      "Epoch: 10 Iteration: 200 Loss: 1.46180\n",
      "Epoch: 10 Iteration: 300 Loss: 1.46203\n",
      "Epoch: 10 Iteration: 400 Loss: 1.47109\n",
      "Epoch: 10 Iteration: 500 Loss: 1.47405\n",
      "Epoch: 10 Iteration: 600 Loss: 1.47165\n",
      "Epoch: 10 Iteration: 700 Loss: 1.47366\n",
      "Epoch: 10 Iteration: 800 Loss: 1.47758\n",
      "Epoch: 10 Iteration: 900 Loss: 1.46191\n",
      "Epoch: 11 Iteration: 0 Loss: 1.46323\n",
      "Epoch: 11 Iteration: 100 Loss: 1.46121\n",
      "Epoch: 11 Iteration: 200 Loss: 1.46205\n",
      "Epoch: 11 Iteration: 300 Loss: 1.46121\n",
      "Epoch: 11 Iteration: 400 Loss: 1.46160\n",
      "Epoch: 11 Iteration: 500 Loss: 1.46124\n",
      "Epoch: 11 Iteration: 600 Loss: 1.46195\n",
      "Epoch: 11 Iteration: 700 Loss: 1.46118\n",
      "Epoch: 11 Iteration: 800 Loss: 1.47980\n",
      "Epoch: 11 Iteration: 900 Loss: 1.46120\n",
      "Epoch: 12 Iteration: 0 Loss: 1.46146\n",
      "Epoch: 12 Iteration: 100 Loss: 1.46861\n",
      "Epoch: 12 Iteration: 200 Loss: 1.46141\n",
      "Epoch: 12 Iteration: 300 Loss: 1.49403\n",
      "Epoch: 12 Iteration: 400 Loss: 1.47504\n",
      "Epoch: 12 Iteration: 500 Loss: 1.47208\n",
      "Epoch: 12 Iteration: 600 Loss: 1.46213\n",
      "Epoch: 12 Iteration: 700 Loss: 1.46123\n",
      "Epoch: 12 Iteration: 800 Loss: 1.46259\n",
      "Epoch: 12 Iteration: 900 Loss: 1.46282\n",
      "Epoch: 13 Iteration: 0 Loss: 1.46355\n",
      "Epoch: 13 Iteration: 100 Loss: 1.46121\n",
      "Epoch: 13 Iteration: 200 Loss: 1.46239\n",
      "Epoch: 13 Iteration: 300 Loss: 1.46118\n",
      "Epoch: 13 Iteration: 400 Loss: 1.48081\n",
      "Epoch: 13 Iteration: 500 Loss: 1.46882\n",
      "Epoch: 13 Iteration: 600 Loss: 1.49381\n",
      "Epoch: 13 Iteration: 700 Loss: 1.46116\n",
      "Epoch: 13 Iteration: 800 Loss: 1.46117\n",
      "Epoch: 13 Iteration: 900 Loss: 1.46116\n",
      "Epoch: 14 Iteration: 0 Loss: 1.46137\n",
      "Epoch: 14 Iteration: 100 Loss: 1.46347\n",
      "Epoch: 14 Iteration: 200 Loss: 1.46310\n",
      "Epoch: 14 Iteration: 300 Loss: 1.46330\n",
      "Epoch: 14 Iteration: 400 Loss: 1.46565\n",
      "Epoch: 14 Iteration: 500 Loss: 1.46148\n",
      "Epoch: 14 Iteration: 600 Loss: 1.46173\n",
      "Epoch: 14 Iteration: 700 Loss: 1.47101\n",
      "Epoch: 14 Iteration: 800 Loss: 1.46136\n",
      "Epoch: 14 Iteration: 900 Loss: 1.46530\n",
      "Epoch: 15 Iteration: 0 Loss: 1.46118\n",
      "Epoch: 15 Iteration: 100 Loss: 1.46241\n",
      "Epoch: 15 Iteration: 200 Loss: 1.46122\n",
      "Epoch: 15 Iteration: 300 Loss: 1.46128\n",
      "Epoch: 15 Iteration: 400 Loss: 1.46422\n",
      "Epoch: 15 Iteration: 500 Loss: 1.46115\n",
      "Epoch: 15 Iteration: 600 Loss: 1.46185\n",
      "Epoch: 15 Iteration: 700 Loss: 1.46127\n",
      "Epoch: 15 Iteration: 800 Loss: 1.46133\n",
      "Epoch: 15 Iteration: 900 Loss: 1.46116\n",
      "Epoch: 16 Iteration: 0 Loss: 1.46256\n",
      "Epoch: 16 Iteration: 100 Loss: 1.46186\n",
      "Epoch: 16 Iteration: 200 Loss: 1.46151\n",
      "Epoch: 16 Iteration: 300 Loss: 1.48378\n",
      "Epoch: 16 Iteration: 400 Loss: 1.48260\n",
      "Epoch: 16 Iteration: 500 Loss: 1.47679\n",
      "Epoch: 16 Iteration: 600 Loss: 1.46579\n",
      "Epoch: 16 Iteration: 700 Loss: 1.46371\n",
      "Epoch: 16 Iteration: 800 Loss: 1.48200\n",
      "Epoch: 16 Iteration: 900 Loss: 1.46176\n",
      "Epoch: 17 Iteration: 0 Loss: 1.46218\n",
      "Epoch: 17 Iteration: 100 Loss: 1.47719\n",
      "Epoch: 17 Iteration: 200 Loss: 1.46124\n",
      "Epoch: 17 Iteration: 300 Loss: 1.46584\n",
      "Epoch: 17 Iteration: 400 Loss: 1.46269\n",
      "Epoch: 17 Iteration: 500 Loss: 1.46553\n",
      "Epoch: 17 Iteration: 600 Loss: 1.46116\n",
      "Epoch: 17 Iteration: 700 Loss: 1.47664\n",
      "Epoch: 17 Iteration: 800 Loss: 1.47355\n",
      "Epoch: 17 Iteration: 900 Loss: 1.46162\n",
      "Epoch: 18 Iteration: 0 Loss: 1.46145\n",
      "Epoch: 18 Iteration: 100 Loss: 1.46843\n",
      "Epoch: 18 Iteration: 200 Loss: 1.46136\n",
      "Epoch: 18 Iteration: 300 Loss: 1.48821\n",
      "Epoch: 18 Iteration: 400 Loss: 1.46162\n",
      "Epoch: 18 Iteration: 500 Loss: 1.46135\n",
      "Epoch: 18 Iteration: 600 Loss: 1.46130\n",
      "Epoch: 18 Iteration: 700 Loss: 1.47671\n",
      "Epoch: 18 Iteration: 800 Loss: 1.47331\n",
      "Epoch: 18 Iteration: 900 Loss: 1.46306\n",
      "Epoch: 19 Iteration: 0 Loss: 1.46201\n",
      "Epoch: 19 Iteration: 100 Loss: 1.46925\n",
      "Epoch: 19 Iteration: 200 Loss: 1.46152\n",
      "Epoch: 19 Iteration: 300 Loss: 1.46137\n",
      "Epoch: 19 Iteration: 400 Loss: 1.46525\n",
      "Epoch: 19 Iteration: 500 Loss: 1.47101\n",
      "Epoch: 19 Iteration: 600 Loss: 1.47006\n",
      "Epoch: 19 Iteration: 700 Loss: 1.46137\n",
      "Epoch: 19 Iteration: 800 Loss: 1.46530\n",
      "Epoch: 19 Iteration: 900 Loss: 1.47655\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (example_data, example_targets) in enumerate(train_loader):\n",
    "        example_data = example_data.to(device)\n",
    "        example_targets = example_targets.to(device)\n",
    "        # run forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(example_data)\n",
    "        loss = F.cross_entropy(output, example_targets)\n",
    "        training_loss.append(loss.item())\n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # calculate loss every 1000 examples\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch} Iteration: {batch_idx} Loss: {loss:0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.46936\n",
      "test accuracy: 0.98726\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (example_data, example_targets) in enumerate(test_loader):\n",
    "            example_data = example_data.to(device)\n",
    "            example_targets = example_targets.to(device)\n",
    "            # run forward pass\n",
    "            output = model(example_data)\n",
    "            test_loss += F.cross_entropy(output, example_targets)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            correct += sum(output == example_targets)\n",
    "\n",
    "print(f'test loss: {test_loss/len(test_loader):0.5f}')\n",
    "print(f'test accuracy: {correct/len(test_loader)/batch_size:0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2e31a78f0>]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "loss_hist = torch.tensor(training_loss).view(70, -1)\n",
    "loss_hist = torch.mean(loss_hist, dim=1)\n",
    "plt.plot(loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress tracker:\n",
    "- 1 layer NN with 10 epochs of training: \n",
    "    - test loss: 1.61052\n",
    "    - test accuracy: 0.88704\n",
    "    \n",
    "- 2 layer NN with 64 size hidden layer, added AdamW optimizer:\n",
    "    - test loss: 1.53824\n",
    "    - test accuracy: 0.92038\n",
    "\n",
    "- 2 layer NN with 128 size hidden layer: (practically no improvement)\n",
    "    - test loss: 1.53825\n",
    "    - test accuracy: 0.91929\n",
    "\n",
    "- 2 layer NN with 64 size hidden layer, added relu after first layer: (relu was necessary ow just liek 1 layer NN)\n",
    "    - test loss: 1.49081\n",
    "    - test accuracy: 0.96865\n",
    "\n",
    "- 3 layer NN with 128 size hidden layer: (architecture is limited)\n",
    "    - test loss: 1.48965\n",
    "    - test accuracy: 0.96785\n",
    "\n",
    "- 1 layer CNN with kernel 3 and padding = 1 joined iwth 1 layer Linear layer: (( appears that regresses to 2 layer NN bc no abstraciton of data))\n",
    "    - test loss: 1.53574\n",
    "    - test accuracy: 0.92267\n",
    "\n",
    "- 2 layer CNN with kernel 3, no padding and increasing channel by 2:\n",
    "    - test loss: 1.49036\n",
    "    - test accuracy: 0.96676\n",
    "\n",
    "- added maxpooling with kernel size 2 in-between conv layers:\n",
    "    - test loss: 1.49294\n",
    "    - test accuracy: 0.96537\n",
    "\n",
    "- relu inbetween convlution layers and deeper channels to 4 and 16: otherwise siimlar to single convlution layer:\n",
    "    - test loss: 1.48902\n",
    "    - test accuracy: 0.97014\n",
    "\n",
    "- larger kernel size - 5:\n",
    "    - test loss: 1.47957\n",
    "    - test accuracy: 0.97850\n",
    "\n",
    "- second linear layer:\n",
    "    - test loss: 1.47536\n",
    "    - test accuracy: 0.98278\n",
    "\n",
    "- dropout for overfitting, only after dense layers: (possibly overfitting after running 10 epochs)\n",
    "    - test loss: 1.47994\n",
    "    - test accuracy: 0.97751\n",
    "\n",
    "- dropout in between convolution layers 20 epoch before overfitting:\n",
    "    - test loss: 1.47057\n",
    "    - test accuracy: 0.98597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(64, 1, 28, 28).to(device)\n",
    "conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 5, kernel_size=5, device=device),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(5, 25, kernel_size=5, device=device),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "lin_layer = nn.Linear(320, 10, device=device)\n",
    "output = conv_layers(a)\n",
    "print(output.shape)\n",
    "output = lin_layer(output.view(-1, 320))\n",
    "# logits = F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
